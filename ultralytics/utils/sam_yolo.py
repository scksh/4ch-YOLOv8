import os
import cv2
import torch
import numpy as np
from PIL import Image
from torchvision import transforms
from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation

# ğŸ”§ ê²½ë¡œ ì„¤ì •
image_dir = "/home/ricky/Data/Animal/images"
output_dir = "/home/ricky/Data/Animal/masks"
os.makedirs(output_dir, exist_ok=True)

# âœ… ëª¨ë¸ ë¡œë“œ
processor = CLIPSegProcessor.from_pretrained("CIDAS/clipseg-rd64-refined")
model = CLIPSegForImageSegmentation.from_pretrained("CIDAS/clipseg-rd64-refined")
model.eval().to("cuda" if torch.cuda.is_available() else "cpu")

# ğŸ¯ í”„ë¡¬í”„íŠ¸ ì„¤ì •
prompt = "a deer"

# ğŸ–¼ ì´ë¯¸ì§€ ìˆœíšŒ
for fname in sorted(os.listdir(image_dir)):
    if not fname.lower().endswith((".jpg", ".png", ".jpeg")):
        continue

    image_path = os.path.join(image_dir, fname)
    image = Image.open(image_path).convert("RGB")

    # âœ‚ï¸ ì…ë ¥ ì „ì²˜ë¦¬
    inputs = processor(
        text=[prompt],
        images=[image],
        return_tensors="pt"
    ).to(model.device)

    with torch.no_grad():
        outputs = model(**inputs)

    # âœ… logits â†’ ë§ˆìŠ¤í¬ ìƒì„±
    mask = torch.sigmoid(outputs.logits)[0][0].cpu().numpy()
    mask = (mask * 255).astype(np.uint8)
    mask_resized = cv2.resize(mask, image.size)

    # âš ï¸ ë§ˆìŠ¤í¬ ìœ íš¨ì„± ê²€ì‚¬
    if mask_resized.shape[0] < 10 or mask_resized.shape[1] < 10:
        print(f"âš ï¸ ë§ˆìŠ¤í¬ ì´ìƒ: {fname}")
        continue

    out_path = os.path.join(output_dir, f"{os.path.splitext(fname)[0]}_mask.png")
    cv2.imwrite(out_path, mask_resized)
    print(f"âœ… ì €ì¥ë¨: {out_path}")
